{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Квазиньютоновские методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## На прошлой лекции\n",
    "\n",
    "- Стохастический градиент\n",
    "- Стохастический градиентный спуск\n",
    "- Сходимость и скорость работы\n",
    "- Адаптивные методы "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## План на сегодня\n",
    "\n",
    "- Сравнение градиентного спуска и метода Ньютона\n",
    "- Построение концепции промежуточных методов\n",
    "- Примеры квазиньютоновских методов\n",
    "- Анализ сложности и сходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Метод Ньютона и градиентный спуск\n",
    "\n",
    "- градиентный метод получен из аппроксимации первого порядка:\n",
    "\n",
    "$$\n",
    "f_G(x) \\approx f(y) + \\langle f'(y), x - y \\rangle + \\frac{1}{2}(x-y)^{\\top} \\frac{1}{\\alpha}I(x - y)\n",
    "$$\n",
    "\n",
    "причём при $\\alpha \\in (0, 1/L], f(x) \\leq f_G(x)$, то есть $f_G$ - глобальная оценка $f(x)$\n",
    "- метод Ньютона получен из аппроксимации второго порядка\n",
    "\n",
    "$$\n",
    "f_N(x) \\approx f(y) + \\langle f'(y), x - y \\rangle + \\frac{1}{2} (x-y)^{\\top}f''(y)(x-y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Недостатки метода Ньютона: напоминание\n",
    "\n",
    "- необходимо хранить гессиан на каждой итерации: $O(n^2)$ памяти\n",
    "- необходимо решать линейные системы: $O(n^3)$ операций\n",
    "- гессиан может оказаться вырожден"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Идея квазиньютоновскизх методов\n",
    "\n",
    "Использовать промежуточную аппроксимацию вида\n",
    "\n",
    "$$\n",
    "f_q(x) \\approx f(y) + \\langle f'(y), x - y \\rangle + \\frac{1}{2} (x-y)^{\\top}{\\color{red}{B(y)}}(x-y),\n",
    "$$\n",
    "\n",
    "которая даёт переход к следующей точке:\n",
    "\n",
    "$$\n",
    "x_{k+1} = x_k - \\alpha_k B^{-1}_k f'(x_k) = x_k - \\alpha_k H_k f'(x_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Как искать $B_{k+1}$?\n",
    "\n",
    "В точке $x_{k+1}$ имеем следующую аппрокисмацию:\n",
    "\n",
    "$$\n",
    "f_q(h) \\approx f(x_{k+1}) + \\langle f'(x_{k+1}), h \\rangle + \\frac{1}{2}h^{\\top}B_{k+1}h\n",
    "$$\n",
    "\n",
    "Из определения, очевидно, что $B_{k+1}$  симметричная и положительно определённая.\n",
    "Какие требования естественно наложить на $f_q(h)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "f_q'(-\\alpha_k h_k) = f'(x_k) \\qquad f'_q(0) = f'(x_{k+1}),\n",
    "$$\n",
    "\n",
    "где первое условие даёт\n",
    "\n",
    "$$\n",
    "f'(x_{k+1}) - \\alpha_k B_{k+1}h_k = f'(x_k),\n",
    "$$\n",
    "\n",
    "а второе выполняется автоматически."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Квазиньютоновское уравнение (Secant equation)\n",
    "\n",
    "Из первого условия получаем\n",
    "\n",
    "$$\n",
    "B_{k+1}s_k = y_k,\n",
    "$$\n",
    "\n",
    "где $s_k = x_{k+1} - x_k$ и $y_k = f'(x_{k+1}) - f'(x_k)$.\n",
    "\n",
    "Это уравнение будет иметь решение только при $s^{\\top}_k y_k > 0$. Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Вопрос:** единственным ли образом определено $B_{k+1}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Как однозначно определить $B_{k+1}$?\n",
    "\n",
    "\\begin{align*}\n",
    "& \\min_B \\| B_k - B \\| \\\\\n",
    "\\text{s.t. } & B = B^{\\top}\\\\\n",
    "& Bs_k = y_k\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DFP (Davidon-Fletcher-Powell)\n",
    "\n",
    "$$\n",
    "B_{k+1} = (I - \\rho_k y_k s^{\\top}_k)B_k(I - \\rho_k s_ky^{\\top}_k) + \\rho_k y_k y^{\\top}_k,\n",
    "$$\n",
    "\n",
    "где $\\rho_k = \\dfrac{1}{y^{\\top}_k s_k}$ и $s_k = x_{k+1} - x_k$ и $y_k = f'(x_{k+1}) - f'(x_k)$\n",
    "\n",
    "или с помощью формулы [Шермана-Морисона-Вудбери](https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula)\n",
    "\n",
    "$$\n",
    "B^{-1}_{k+1} = H_{k+1} = H_k - \\dfrac{H_ky_k y_k^{\\top}H_k}{y^{\\top}_kH_ky_k} + \\dfrac{s_ks^{\\top}_k}{y^{\\top}_ks_k}\n",
    "$$\n",
    "\n",
    "**Вопрос:** какой ранг у разности матриц $B_{k+1} (H_{k+1})$ и $B_{k} (H_{k})$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Вывод\n",
    "\n",
    "Общая идея квазиньютоновских методов: \n",
    "\n",
    "- вместо полного пересчёта гессиана на каждой итерации обновлять текущую его аппроксимацию с помощью легко вычислимого преобразования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Метод BFGS\n",
    "<img src=\"./bfgs.png\" width=500>\n",
    "\n",
    "**Вопрос:** какая естественная модификация метода DFP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\begin{align*}\n",
    "& \\min_H \\| H_k - H \\| \\\\\n",
    "\\text{s.t. } & H = H^{\\top}\\\\\n",
    "& Hy_k = s_k\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Формула пересчёта для метода BFGS:\n",
    "\n",
    "$$\n",
    "H_{k+1} = (I - \\rho_k s_ky^{\\top}_k)H_k(I - \\rho_k y_k s^{\\top}_k) + \\rho_k s_k s^{\\top}_k,\n",
    "$$\n",
    "\n",
    "где $\\rho_k = \\dfrac{1}{y^{\\top}_k s_k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сложность вычислений\n",
    "\n",
    "- Вместо необходимости решать системы линейных уравнений за $O(n^3)$ необходимо оперировать с матрицами и векторами за $O(n^2)$. Проверьте, что вы понимаете как это делать на основе вышеприведённых формул\n",
    "\n",
    "- Хранить полные матрицы всё ещё надо, то есть проблема с квадратичной сложностью по паимяти никуда не делась"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Идея снижения потребления памяти\n",
    "\n",
    "- В методе BFGS нужна не сама матрица $H$, а только функция умножения её на вектор \n",
    "- Поскольку требуется локальная оценка гессиана, старые значения векторов $s$ и $y$ могут портить текущую оценку\n",
    "\n",
    "**Идея**\n",
    "\n",
    "- Хранить $k \\ll n$ последних векторов $s$ и $y$ - снижение требуемой памяти с $n^2$ до $kn$\n",
    "- Выполнение умножения на вектор рекурсивно, без явного формирования матрицы $H$ за $O(nk)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Метод LBFGS\n",
    "\n",
    "- Инициализируем матрицу $H_0$, чаще всего это некоторая диагональная матрица\n",
    "- Копим первые $k$ пар векторов $s$ и $y$, в процессе рекурсивно умножаем на матрицу в \"распределённом виде\"\n",
    "- Для $k+1$ пары $(s, y)$ удаляем первую пару и обновляем матрицу $H_0$ \n",
    "- Продолжаем такие итерации до сходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Умножение гессиана на вектор\n",
    "\n",
    "```python\n",
    "def get_lbfgs_direction(x):\n",
    "    \n",
    "    if H is None:\n",
    "        \n",
    "        current_grad = grad(x)\n",
    "        \n",
    "        return -current_grad\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        q = current_grad\n",
    "        \n",
    "        alpha = np.zeros(len(s_hist))\n",
    "        \n",
    "        rho = np.zeros(len(s_hist))\n",
    "        \n",
    "        for i in range(len(s_hist) - 1, -1, -1):\n",
    "            \n",
    "            rho[i] = 1. / s_hist[i].dot(y_hist[i])\n",
    "            \n",
    "            alpha[i] = s_hist[i].dot(q) * rho[i]\n",
    "            \n",
    "            q = q - alpha[i] * y_hist[i]\n",
    "            \n",
    "        r = q * H\n",
    "        \n",
    "        for i in range(len(s_hist)):\n",
    "            \n",
    "            beta = rho[i] * y_hist[i].dot(r)\n",
    "            \n",
    "            r = r + s_hist[i] * (alpha[i] - beta)\n",
    "            \n",
    "    return -r\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Сходимость\n",
    "\n",
    "- Квазиньютоновские методы относятся к методам, которые используют **нелинейные** преобразования градиентов\n",
    "- Теоретические результаты по их сходимости довольны скудны и находятся в стадии разработки\n",
    "- Экспериментально такие методы сходятся быстро и являются основными методами решения задач большой размерности при доступном **точном** градиенте\n",
    "- Более формально есть результаты об их сверхлинейной сходимости\n",
    "- Обобщения такого подхода на случай стохастической оценки градиента находятся в стадии исследований"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Выводы\n",
    "\n",
    "- Приближение гессиана и аналитическое вычисление обратной матрицы снижает сложность одной итерации\n",
    "- Неявное хранение матрицы и ограниченное использование истории повышвет скорость сходимости\n",
    "- Обобщения с использованием стохастической оценки градиента не дают "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
