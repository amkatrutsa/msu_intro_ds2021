{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e47bfc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Стохастические градиентные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872adc0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## На прошлой лекции\n",
    "\n",
    "- Быстрый градиентный метод\n",
    "- Сходимость и отличие от метода тяжёлого шарика\n",
    "- Метод Ньютона\n",
    "- Вычислительная сложность и скорость сходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1e4cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## План на сегодня\n",
    "\n",
    "- Стохастический градиент: что это и чем отличается от обычного?\n",
    "- Когда и как именно можно его использовать для решения задачи?\n",
    "- Особенности адаптированного подбора шага в таких методах\n",
    "- Сравнение сходимости с детерминированным методами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80cfb0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Постановка задачи\n",
    "\n",
    "- Что мы рассматривали ранее\n",
    "\n",
    "$$ \\min_x f(x) $$\n",
    "\n",
    "- Что будем рассматривать сегодня\n",
    "\n",
    "$$ \\min_x \\frac{1}{N} \\sum_{i=1}^N f_i(x) $$\n",
    "\n",
    "- Теперь знаем как функция выглядит\n",
    "- Больше информации о функции - больше возможностей к построению более эффективных методов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b8a275",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Стохастический градиент\n",
    "\n",
    "- Точный градиент\n",
    "\n",
    "$$ \\frac{1}{N} \\sum_{i=1}^N f_i'(x) $$\n",
    "\n",
    "- **Стохастический** градиент \n",
    "\n",
    "$$ \\frac{1}{|\\mathcal{I}|} \\sum_{i \\in \\mathcal{I}} f_i'(x) $$\n",
    "\n",
    "- Идея: идея используем только некоторые слагаемые\n",
    "- Как вы думаете как выбирать какие $f_i$ использовать и почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cbc9ab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Стохастический градиентный спуск (SGD)\n",
    "\n",
    "$$ x_{k+1} = x_k - \\alpha_k g_k, \\qquad g_k = \\frac{1}{|\\mathcal{I}_k|} \\sum_{i \\in \\mathcal{I}_k} f_i'(x) $$\n",
    "\n",
    "- Сходимость определяется через усреднение по истории\n",
    "- Для выпуклых функций сходимость $\\mathcal{O}(1 / \\sqrt{k})$\n",
    "- Для сильно выпуклых функций $\\mathcal{O}(1 / k)$\n",
    "\n",
    "- Все скорости сходимости стали **медленнее**, чем были для классического градиентного спуска\n",
    "- Причина: направление движения в SGD **не обязано** быть направлением убывания\n",
    "- Используется постоянный шаг или проводится изменение по некоторому расписанию: много эвристик"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6deecf1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Какие плюсы есть у неточного вычисления градиента?\n",
    "\n",
    "- Вычисляется быстрее\n",
    "- Если у функции много локальных минимумов, то неточный градиент может приводить к посещению большого числа локальных минимумов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a134c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Применение к обучению нейросетей\n",
    "\n",
    "- Напомним, что нейросеть - это суперпозиция простых функций (линейных и нелинейных), у которых есть параметры\n",
    "- Для заданной функции потерь, которая как раз таки и представляется в виде суммы конечного, но большого числа функций, ищутся оптимальные параметры\n",
    "- Минимизация функции потерь - формализация процесса обучения нейросети\n",
    "- Каждое слагаемое в функции потерь - это величина ошибки при обработке одного объекта, например одного изображения или анкеты одного потенциального заёмщика\n",
    "- Стандартные архитектуры не являются выпуклыми по параметрам, поэтому возможность \"побывать\" в различных локальных минимумах - важное свойство методов из этого класса  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c8ee5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Недостатки SGD\n",
    "\n",
    "- Сходимость можно измерять только на основании стабилизации значения целевой функции\n",
    "- Небольшой размер множества индексов приводит к высокой вариативности направлений на различных итерациях. Формально, это свойство называется большой дисперсией в оценке градиента\n",
    "- Неудачный размер шага может приводить либо к расходимости либо к очень медленной сходимости метода, так как это константа для всех элементов вектора параметров  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f350b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ускоренные стохастические методы\n",
    "\n",
    "- По аналогии с ускорением классического градиентного спуска можно ускорять и его стохастическую модификацию\n",
    "- Однако улучшения теоретических оценок не происходит хотя на практике методы работают быстрее\n",
    "- Каким образом можно улучшить теоретические оценки?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c06465",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Метод усреднения стохастических градиентов (Stochastic averaged gradient method)\n",
    "\n",
    "- Сначала вычислим все $g_i = f_i(x_0)$ и **сохраним**\n",
    "- Далее на итерации $k+1$ вычислим $f_{i_k}(x_k) = h_k$\n",
    "\n",
    "\n",
    "$$ x_{k+1} = x_k - \\alpha \\left(\\frac1N h_k - \\frac1N g_{i_k} + \\frac{1}{N}\\sum_{i=1}^N g_i\\right) $$\n",
    "$$ g_{i_k} = h_k $$\n",
    "\n",
    "- Для такого метода показано [тут](https://arxiv.org/pdf/1309.2388.pdf), что оценки сходимости совпадают со сходимостью классического градиентного спуска "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b325af3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Адаптивные методы\n",
    "\n",
    "- Размер шага свой для каждого элемента\n",
    "- Размер шага подбирается на основе предыдущих значений стохастического градиента\n",
    "- Скользящее среднее от вычисленных стохастических градиентов повышает устойчивость всего процесса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf113b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adagrad\n",
    "\n",
    "\\begin{align*}\n",
    "& g_k = \\sum_{i \\in \\mathcal{I}} f'_i(x_k)\\\\\n",
    "& r = r + g_k \\cdot g_k\\\\\n",
    "& h_k = -\\frac{\\varepsilon}{\\delta + \\sqrt{r}} \\cdot g_k\\\\\n",
    "& x_{k+1} = x_k + h_k\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "- Все операции выполняются поэлементно\n",
    "- Задаётся базовый размер шага $\\varepsilon$\n",
    "- Эквивалентно диагональному шкалированию вектора градиента\n",
    "- Какой недостаток у такого метода?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1d8a37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adam\n",
    "\n",
    "\\begin{align*}\n",
    "& g_k = \\sum_{i \\in \\mathcal{I}} f'_i(x_k)\\\\\n",
    "& r = \\rho_2r + (1 - \\rho_2) g_k \\cdot g_k\\\\\n",
    "& s = \\rho_1 s + (1 - \\rho_1) g_k\\\\\n",
    "& \\hat{s} = \\frac{s}{1 - \\rho_1^k}\\\\\n",
    "& \\hat{r} = \\frac{r}{1 - \\rho_2^k}\\\\\n",
    "& h_k = -\\frac{\\varepsilon \\hat{s}}{\\delta + \\sqrt{\\hat{r}}} \\\\\n",
    "& x_{k+1} = x_k + h_k\n",
    "\\end{align*}\n",
    "\n",
    "- Типичные значения параметров $\\rho_1 = 0.9, \\rho_2 = 0.999$\n",
    "- Для обьновления параметров используется сглаженные версии градиентов и их поэлементных квадратов\n",
    "- Устойчиво работает на большом классе задач обучения нейросетей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2994cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Сходимость адаптивных методов\n",
    "\n",
    "- Законченная теория сходимости таких методов на данный момент отсутствует\n",
    "- Множество эмпирических фактов говорит, что такие методы требуют существенно меньше времени\n",
    "- Однако есть и недостатки, связанные с возможностью переобучения "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31b881",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Другие модификации\n",
    "\n",
    "<img src=\"optax_common.png\" width=400>\n",
    "\n",
    "- Список взят из документации к [optax](https://optax.readthedocs.io/en/latest/)\n",
    "- Как вы думаете, что можно улучшать в рассмотренных выше методах?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebff8efb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Выводы\n",
    "\n",
    "- Постановка задачи пригодная для использования стохастического градиента\n",
    "- Стохастические градиентные методы - мощный инструмент для обучения нейросетей\n",
    "- Достоинства и недостатки таких методов\n",
    "- Адаптивные методы выбора шага"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
